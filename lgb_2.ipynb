{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "all_data = pd.read_csv('sales所在周次节假日.csv')\n",
    "all_data.rename(columns={'店铺名称':'store','地理位置指数':'position','年份':'years','周次':'weeks of year','是否包含法定节假日':'Isholiday','季节':'season','大类':'item','销量':'sales','均价':'prices','促销':'discount'},inplace=True)\n",
    "all_data['weeks'] = all_data['weeks of year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lin/anaconda3/envs/boost/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "a = all_data\n",
    "week_5 = a.loc[lambda a : a['years'] == 2015]\n",
    "week_6 = a.loc[lambda a : a['years'] == 2016]\n",
    "week_6['weeks'] += 53\n",
    "a = pd.concat([week_5,week_6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#map店铺名称\n",
    "name = a['store']\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(name)\n",
    "list(name)\n",
    "le.transform(name)\n",
    "tmp = le.transform(name)\n",
    "a['store'] = tmp\n",
    "\n",
    "#map合并大类\n",
    "category = a['item']\n",
    "le.fit(category)\n",
    "list(category)\n",
    "le.transform(category)\n",
    "tmp = le.transform(category)\n",
    "a['item'] = tmp\n",
    "\n",
    "#map季节\n",
    "season = a['season']\n",
    "le.fit(season)\n",
    "list(season)\n",
    "le.transform(season)\n",
    "tmp = le.transform(season)\n",
    "a['season'] = tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = a\n",
    "#masked_series = (df['years']==2016) & (df['weeks'].isin([53,54,55]))\n",
    "#masked_series2 = (df['years']==2016) & (~(df['weeks'].isin([53,54,55])))\n",
    "#df.loc[(masked_series), 'train_or_test'] = 'test'\n",
    "#df.loc[(masked_series2), 'train_or_test'] = 'no_train'\n",
    "#print('Train shape: {}'.format(df.loc[df['years']==2015,:].shape))\n",
    "#print('Test shape: {}'.format(df.loc[df.train_or_test=='test',:].shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_n = df.drop(['train_or_test'],axis=1)\n",
    "df_n = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>position</th>\n",
       "      <th>years</th>\n",
       "      <th>weeks of year</th>\n",
       "      <th>Isholiday</th>\n",
       "      <th>season</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "      <th>prices</th>\n",
       "      <th>discount</th>\n",
       "      <th>weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.474704</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11394</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.450479</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       store  position  years  weeks of year  Isholiday  season  item  sales  \\\n",
       "5027       8         7   2015             21          0       2    11      4   \n",
       "11394     18         1   2016             20          0       2    11      1   \n",
       "\n",
       "         prices  discount  weeks  \n",
       "5027   1.609438  0.474704     21  \n",
       "11394  0.693147  0.450479     73  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_n['sales'] = np.log1p(df_n.sales.values)\n",
    "df_n['prices'] = np.log1p(df_n.sales.values)\n",
    "df_n.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>position</th>\n",
       "      <th>years</th>\n",
       "      <th>weeks of year</th>\n",
       "      <th>Isholiday</th>\n",
       "      <th>season</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "      <th>prices</th>\n",
       "      <th>discount</th>\n",
       "      <th>weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18163.000000</td>\n",
       "      <td>18163.000000</td>\n",
       "      <td>18163.000000</td>\n",
       "      <td>18163.000000</td>\n",
       "      <td>18163.000000</td>\n",
       "      <td>18163.000000</td>\n",
       "      <td>18163.00000</td>\n",
       "      <td>18163.000000</td>\n",
       "      <td>18163.000000</td>\n",
       "      <td>18163.000000</td>\n",
       "      <td>18163.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.547156</td>\n",
       "      <td>5.501569</td>\n",
       "      <td>2015.552992</td>\n",
       "      <td>27.652701</td>\n",
       "      <td>0.185432</td>\n",
       "      <td>1.597864</td>\n",
       "      <td>5.41992</td>\n",
       "      <td>7.880031</td>\n",
       "      <td>1.697586</td>\n",
       "      <td>0.364135</td>\n",
       "      <td>56.961295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.695615</td>\n",
       "      <td>2.597241</td>\n",
       "      <td>0.497198</td>\n",
       "      <td>15.181708</td>\n",
       "      <td>0.388658</td>\n",
       "      <td>1.048877</td>\n",
       "      <td>2.71015</td>\n",
       "      <td>16.436671</td>\n",
       "      <td>0.880375</td>\n",
       "      <td>0.089089</td>\n",
       "      <td>30.663260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.305955</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.368088</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.420665</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>912.000000</td>\n",
       "      <td>6.816736</td>\n",
       "      <td>0.902023</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              store      position         years  weeks of year     Isholiday  \\\n",
       "count  18163.000000  18163.000000  18163.000000   18163.000000  18163.000000   \n",
       "mean      14.547156      5.501569   2015.552992      27.652701      0.185432   \n",
       "std        8.695615      2.597241      0.497198      15.181708      0.388658   \n",
       "min        0.000000      1.000000   2015.000000       1.000000      0.000000   \n",
       "25%        7.000000      7.000000   2015.000000      14.000000      0.000000   \n",
       "50%       14.000000      7.000000   2016.000000      28.000000      0.000000   \n",
       "75%       22.000000      7.000000   2016.000000      40.000000      0.000000   \n",
       "max       29.000000      7.000000   2016.000000      53.000000      1.000000   \n",
       "\n",
       "             season         item         sales        prices      discount  \\\n",
       "count  18163.000000  18163.00000  18163.000000  18163.000000  18163.000000   \n",
       "mean       1.597864      5.41992      7.880031      1.697586      0.364135   \n",
       "std        1.048877      2.71015     16.436671      0.880375      0.089089   \n",
       "min        0.000000      0.00000      1.000000      0.693147      0.032120   \n",
       "25%        1.000000      3.00000      2.000000      1.098612      0.305955   \n",
       "50%        2.000000      6.00000      4.000000      1.609438      0.368088   \n",
       "75%        2.000000      7.00000      9.000000      2.302585      0.420665   \n",
       "max        3.000000     11.00000    912.000000      6.816736      0.902023   \n",
       "\n",
       "              weeks  \n",
       "count  18163.000000  \n",
       "mean      56.961295  \n",
       "std       30.663260  \n",
       "min        1.000000  \n",
       "25%       31.000000  \n",
       "50%       59.000000  \n",
       "75%       84.000000  \n",
       "max      106.000000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\ndef one_hot_encoder(df_n, ohe_cols=['store','item','weeks of years','isholiday','season','item']):\\n\\n#    One-Hot Encoder function\\n    print('Creating OHE features..\\nOld df shape:{}'.format(df.shape))\\n    df_n = pd.get_dummies(df_n, columns=ohe_cols)\\n    print('New df shape:{}'.format(df.shape))\\n    return df_n\\n\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''\n",
    "def one_hot_encoder(df_n, ohe_cols=['store','item','weeks of years','isholiday','season','item']):\n",
    "\n",
    "#    One-Hot Encoder function\n",
    "    print('Creating OHE features..\\nOld df shape:{}'.format(df.shape))\n",
    "    df_n = pd.get_dummies(df_n, columns=ohe_cols)\n",
    "    print('New df shape:{}'.format(df.shape))\n",
    "    return df_n\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = df_n[lambda df_n: df_n['sales'] > 200]\n",
    "#outlier.index\n",
    "df_n = df_n.drop([2215, 2222, 2341, 2511, 2518, 2984, 5672, 2583, 2730, 2890, 2897,8064])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>position</th>\n",
       "      <th>years</th>\n",
       "      <th>weeks of year</th>\n",
       "      <th>Isholiday</th>\n",
       "      <th>season</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "      <th>prices</th>\n",
       "      <th>discount</th>\n",
       "      <th>weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18151.000000</td>\n",
       "      <td>18151.000000</td>\n",
       "      <td>18151.000000</td>\n",
       "      <td>18151.000000</td>\n",
       "      <td>18151.000000</td>\n",
       "      <td>18151.000000</td>\n",
       "      <td>18151.000000</td>\n",
       "      <td>18151.000000</td>\n",
       "      <td>18151.000000</td>\n",
       "      <td>18151.000000</td>\n",
       "      <td>18151.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.553358</td>\n",
       "      <td>5.500909</td>\n",
       "      <td>2015.553082</td>\n",
       "      <td>27.650928</td>\n",
       "      <td>0.185499</td>\n",
       "      <td>1.597928</td>\n",
       "      <td>5.420693</td>\n",
       "      <td>7.643160</td>\n",
       "      <td>1.694903</td>\n",
       "      <td>0.364187</td>\n",
       "      <td>56.964299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.694909</td>\n",
       "      <td>2.597623</td>\n",
       "      <td>0.497188</td>\n",
       "      <td>15.179253</td>\n",
       "      <td>0.388713</td>\n",
       "      <td>1.048774</td>\n",
       "      <td>2.710368</td>\n",
       "      <td>12.066473</td>\n",
       "      <td>0.874364</td>\n",
       "      <td>0.089091</td>\n",
       "      <td>30.658825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.306071</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.368168</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.420708</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>5.278115</td>\n",
       "      <td>0.902023</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              store      position         years  weeks of year     Isholiday  \\\n",
       "count  18151.000000  18151.000000  18151.000000   18151.000000  18151.000000   \n",
       "mean      14.553358      5.500909   2015.553082      27.650928      0.185499   \n",
       "std        8.694909      2.597623      0.497188      15.179253      0.388713   \n",
       "min        0.000000      1.000000   2015.000000       1.000000      0.000000   \n",
       "25%        7.000000      7.000000   2015.000000      14.000000      0.000000   \n",
       "50%       14.000000      7.000000   2016.000000      28.000000      0.000000   \n",
       "75%       22.000000      7.000000   2016.000000      40.000000      0.000000   \n",
       "max       29.000000      7.000000   2016.000000      53.000000      1.000000   \n",
       "\n",
       "             season          item         sales        prices      discount  \\\n",
       "count  18151.000000  18151.000000  18151.000000  18151.000000  18151.000000   \n",
       "mean       1.597928      5.420693      7.643160      1.694903      0.364187   \n",
       "std        1.048774      2.710368     12.066473      0.874364      0.089091   \n",
       "min        0.000000      0.000000      1.000000      0.693147      0.032120   \n",
       "25%        1.000000      3.000000      2.000000      1.098612      0.306071   \n",
       "50%        2.000000      6.000000      4.000000      1.609438      0.368168   \n",
       "75%        2.000000      7.000000      9.000000      2.302585      0.420708   \n",
       "max        3.000000     11.000000    195.000000      5.278115      0.902023   \n",
       "\n",
       "              weeks  \n",
       "count  18151.000000  \n",
       "mean      56.964299  \n",
       "std       30.658825  \n",
       "min        1.000000  \n",
       "25%       31.000000  \n",
       "50%       59.000000  \n",
       "75%       84.000000  \n",
       "max      106.000000  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 106\n",
      "2 106\n",
      "3 106\n",
      "4 106\n",
      "5 106\n",
      "6 106\n",
      "7 106\n",
      "8 106\n",
      "9 106\n",
      "10 106\n",
      "11 106\n",
      "12 106\n",
      "13 79\n",
      "14 106\n",
      "16 106\n",
      "17 106\n",
      "18 106\n",
      "19 106\n",
      "21 106\n",
      "22 106\n",
      "23 106\n",
      "24 106\n",
      "25 106\n",
      "26 92\n",
      "27 106\n",
      "28 106\n",
      "29 106\n",
      "1 17\n",
      "15 17\n",
      "20 29\n"
     ]
    }
   ],
   "source": [
    "for i in df_n['store'].drop_duplicates():\n",
    "    a = df_n[lambda df_n : df_n['store'] == i]\n",
    "    b = a['weeks'].drop_duplicates().count()\n",
    "    print (i,b)\n",
    "    if b != 106:\n",
    "        s_ = df_n[lambda df_n: df_n['store'] == i]\n",
    "        index_s = s_.index\n",
    "        df_n = df_n.drop(index_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_n = df_n.drop(['prices','discount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_n[lambda df_n: df_n['years']==2015]\n",
    "t1 = df_n[lambda df_n: df_n['weeks']==57]\n",
    "t2 = df_n[lambda df_n: df_n['weeks']==58]\n",
    "t3 = df_n[lambda df_n: df_n['weeks']==59]\n",
    "#test = pd.concat([t1,t2,t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test = df_n[lambda df_n: df_n['years'] == 2016]\n",
    "test = all_test[lambda all_test: all_test['weeks'] <82]\n",
    "val_test = all_test[lambda all_test: all_test['weeks'] < 67]\n",
    "#test = tmp[lambda tmp: tmp['weeks']<65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = one_hot_encoder(train, ohe_cols=['store','item','weeks of year','Isholiday','season','item']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['sales']\n",
    "y_test = test['sales']\n",
    "X_train = train.drop('sales', axis=1)\n",
    "X_test = test.drop('sales', axis=1)\n",
    "y_val_test = val_test['sales']\n",
    "X_val_test = val_test.drop('sales',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l2: 119.196\tvalid_0's l1: 6.45683\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's l2: 97.1557\tvalid_0's l1: 5.8105\n",
      "[3]\tvalid_0's l2: 79.4668\tvalid_0's l1: 5.23155\n",
      "[4]\tvalid_0's l2: 64.9869\tvalid_0's l1: 4.70837\n",
      "[5]\tvalid_0's l2: 53.3585\tvalid_0's l1: 4.23937\n",
      "[6]\tvalid_0's l2: 43.7325\tvalid_0's l1: 3.81561\n",
      "[7]\tvalid_0's l2: 35.9268\tvalid_0's l1: 3.43422\n",
      "[8]\tvalid_0's l2: 29.6238\tvalid_0's l1: 3.09139\n",
      "[9]\tvalid_0's l2: 24.556\tvalid_0's l1: 2.78289\n",
      "[10]\tvalid_0's l2: 20.4\tvalid_0's l1: 2.5052\n",
      "[11]\tvalid_0's l2: 17.0409\tvalid_0's l1: 2.25543\n",
      "[12]\tvalid_0's l2: 14.3176\tvalid_0's l1: 2.03076\n",
      "[13]\tvalid_0's l2: 12.1156\tvalid_0's l1: 1.82874\n",
      "[14]\tvalid_0's l2: 10.3163\tvalid_0's l1: 1.6466\n",
      "[15]\tvalid_0's l2: 8.86936\tvalid_0's l1: 1.48522\n",
      "[16]\tvalid_0's l2: 7.73361\tvalid_0's l1: 1.34125\n",
      "[17]\tvalid_0's l2: 6.81033\tvalid_0's l1: 1.21189\n",
      "[18]\tvalid_0's l2: 6.05385\tvalid_0's l1: 1.09531\n",
      "[19]\tvalid_0's l2: 5.43438\tvalid_0's l1: 0.990257\n",
      "[20]\tvalid_0's l2: 4.92962\tvalid_0's l1: 0.896509\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 4.92962\tvalid_0's l1: 0.896509\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "The rmse of prediction is: 3.030698935961428\n",
      "The R^2 of prediction is: 0.9534039189195698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "print('Saving model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_val_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_val_test, y_pred) ** 0.5)\n",
    "print('The R^2 of prediction is:', r2_score(y_val_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = pd.DataFrame(y_pred,columns = ['pred'])\n",
    "y_val_test = pd.DataFrame(y_val_test)\n",
    "y_val_test_ = y_val_test.reset_index().drop(['index'],axis=1)\n",
    "y_pred_['test'] = y_val_test_['sales']\n",
    "#y_pred_\n",
    "#y_val_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_pred, y_true):\n",
    "    # calculate error\n",
    "    denom = (abs(y_pred) + abs(y_true)) / 2\n",
    "    errors = abs(y_pred - y_true) / denom\n",
    "    return 100 *np.sum(errors) / len(y_true)\n",
    "\n",
    "#print(smape(y_pred_['pred'],y_pred_['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_pred, y_true):\n",
    "    errors = abs(y_pred - y_true)\n",
    "    return np.sum(errors) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_pred, y_true):\n",
    "    # calculate error\n",
    "    #denom = (abs(y_pred) + abs(y_true)) / 2\n",
    "    errors = abs((y_pred - y_true) / y_true)\n",
    "    return 100 *np.sum(errors) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "                    1:[1,2,3],\n",
    "                    2:[1,2,3]\n",
    "})\n",
    "\n",
    "mape(df[1] ,df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 0.16285758600763967\n",
      "The R^2 of prediction is: 0.999864511072736\n",
      "The smape of prediction is: 0.01450211327219326\n",
      "The mae of prediction is: 0.012770137524557957\n",
      "The mape of prediction is: 0.014423853677053317\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBRegressor(n_jobs=-1)\n",
    "\n",
    "model_f = model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict\n",
    "y_pred = model_f.predict(X_val_test)\n",
    "\n",
    "# eval\n",
    "# print('The rmse of prediction is:', mean_squared_error(y_val_test, y_pred ** 0.5))\n",
    "# print('The R^2 of prediction is:', r2_score(y_val_test, y_pred))\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred = round(y_pred)\n",
    "df = pd.concat([y_val_test.reset_index().drop(['index'],axis=1),round(y_pred[0])],axis=1)\n",
    "\n",
    "print('The rmse of prediction is:', mean_squared_error(df[0],df['sales']) ** 0.5)\n",
    "print('The R^2 of prediction is:', r2_score(df[0],df['sales']))\n",
    "print('The smape of prediction is:',smape(df[0],df['sales']))\n",
    "print('The mae of prediction is:',mae(df[0],df['sales']))\n",
    "print('The mape of prediction is:',mape(df[0],df['sales']))\n",
    "#pd.concat([list(y_pred[0]),list(y_val_test['sales'])],axis=1)\n",
    "#pd.concat([y_val_test.reset_index().drop(['index'],axis=1),round(y_pred[0])],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_pred, y_true):\n",
    "    # calculate error\n",
    "    denom = (abs(y_pred) + abs(y_true)) / 2\n",
    "    errors = abs(y_pred - y_true) / denom\n",
    "    return 100 * np.sum(errors) / len(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 1.862641181575228\n",
      "The R^2 of prediction is: 0.9823996136752655\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "#                               learning_rate=0.05, n_estimators=720,\n",
    "#                               max_bin = 55, bagging_fraction = 0.8,\n",
    "#                               bagging_freq = 5, feature_fraction = 0.2319,\n",
    "#                               feature_fraction_seed=9, bagging_seed=9,\n",
    "#                               min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "# model_lgb = lgb.LGBMRegressor(boosting='goss')\n",
    "model_lgb = lgb.LGBMRegressor(njob=-1)\n",
    "\n",
    "model_lgb_t = model_lgb.fit(X_train,y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model_lgb_t.predict(X_val_test)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_val_test, y_pred) ** 0.5)\n",
    "print('The R^2 of prediction is:', r2_score(y_val_test, y_pred))\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "#plt.figure(figsize=(12,6))\n",
    "lgb.plot_importance(model_lgb_t, max_num_features=30)\n",
    "plt.title(\"Featurertances of lgb\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [2, 2]]\n",
    "y = [0.5, 2.5]\n",
    "clf = svm.SVR()\n",
    "clf.fit(X, y) \n",
    "\n",
    "\n",
    "\n",
    "clf.predict([[1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 9.447568956474656\n",
      "The R^2 of prediction is: 0.5472025835498152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor(activation='identity')\n",
    "\n",
    "model_f = model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict\n",
    "y_pred = model_f.predict(X_val_test)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_val_test, y_pred) ** 0.5)\n",
    "print('The R^2 of prediction is:', r2_score(y_val_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 4.268463479598912\n",
      "The R^2 of prediction is: 0.907571279878607\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "#X, y = make_regression(n_features=4, n_informative=2,\n",
    "#                       random_state=0, shuffle=False)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0,\n",
    "                             n_estimators=100)\n",
    "model_r = regr.fit(X_train, y_train)  \n",
    "\n",
    "# predict\n",
    "y_pred = model_r.predict(X_val_test)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_val_test, y_pred) ** 0.5)\n",
    "print('The R^2 of prediction is:', r2_score(y_val_test, y_pred))\n",
    "\n",
    "print(regr.feature_importances_)\n",
    "\n",
    "#print(regr.predict([[0, 0, 0, 0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 14.471665234827642\n",
      "The R^2 of prediction is: -0.06243119675438025\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "model = svm.SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "    gamma='auto', kernel='rbf', max_iter=-1, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "model_f = model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict\n",
    "y_pred = model_f.predict(X_val_test)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_val_test, y_pred) ** 0.5)\n",
    "print('The R^2 of prediction is:', r2_score(y_val_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-1.90234024e-02  1.33226763e-15  6.39718448e-02 -3.24211769e-01\n",
      "  1.05183302e-02  1.19004422e+01 -7.96497881e+00 -9.24662836e-03]\n",
      "Mean squared error: 44.86\n",
      "Variance score: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "#diabetes_X_train = diabetes_X[:-20]\n",
    "#diabetes_X_test = diabetes_X[-20:]\n",
    "diabetes_X_train = df_n[lambda df_n: df_n['years'] == 2015][['store', 'years',  'Isholiday', 'season','item', 'prices', 'discount', 'weeks']]\n",
    "diabetes_X_test = df_n[lambda df_n: df_n['years'] == 2016][['store', 'years',  'Isholiday', 'season','item', 'prices', 'discount', 'weeks']]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "#diabetes_y_train = diabetes.target[:-20]\n",
    "#diabetes_y_test = diabetes.target[-20:]\n",
    "diabetes_y_train = df_n[lambda df_n: df_n['years'] == 2015]['sales']\n",
    "diabetes_y_test = df_n[lambda df_n: df_n['years'] == 2016]['sales']\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients:', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.40102189402621\n"
     ]
    }
   ],
   "source": [
    "def smape(y_pred, y_true):\n",
    "    # calculate error\n",
    "    denom = (abs(y_pred) + abs(y_true)) / 2\n",
    "    errors = abs(y_pred - y_true) / denom\n",
    "    return 100 * np.sum(errors) / len(y_true)\n",
    "\n",
    "print(smape(diabetes_y_pred,diabetes_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of weights not compatible with specified axis.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ffeeb5808e2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mregL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiabetes_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiabetes_y_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mregR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiabetes_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiabetes_y_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdiabetes_y_pred_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiabetes_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boost/lib/python3.7/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boost/lib/python3.7/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    497\u001b[0m         X, y, X_offset, y_offset, X_scale = self._preprocess_data(\n\u001b[1;32m    498\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# temporary fix for fitting the intercept with sparse data using 'sag'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boost/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(X, y, fit_intercept, normalize, copy, sample_weight, return_mean, check_input)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mX_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mX_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boost/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 413\u001b[0;31m                     \"Length of weights not compatible with specified axis.\")\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;31m# setup wgt to broadcast along axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of weights not compatible with specified axis."
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import datasets\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 8]\n",
    "\n",
    "regL = linear_model.Lasso\n",
    "regR = linear_model.Ridge\n",
    "\n",
    "regL = linear_model.Lasso(alpha=0.1)\n",
    "regR = linear_model.Ridge(alpha=0.5)\n",
    "df_nR = df_n[lambda df_n: df_n['years'] == 2015].drop(['sales'],axis=1)\n",
    "#diabetes_X_train = df_n[lambda df_n: df_n['years'] == 2015]\n",
    "df_nR = df_n[lambda df_n: df_n['years'] == 2016].drop(['sales'],axis=1)\n",
    "#diabetes_X_test = df_n[lambda df_n: df_n['years'] == 2016]\n",
    "\n",
    "diabetes_y_train = df_n[lambda df_n: df_n['years'] == 2015]['sales']\n",
    "diabetes_y_test = df_n[lambda df_n: df_n['years'] == 2016]['sales']\n",
    "\n",
    "regL.fit(diabetes_X_train, diabetes_y_train,[0,1])\n",
    "regR.fit(diabetes_X_train, diabetes_y_train,[0,1])\n",
    "\n",
    "diabetes_y_pred_L = regL.predict(diabetes_X_test)\n",
    "diabetes_y_pred_R = regR.predict(diabetes_X_test)\n",
    "\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients:', regL.coef_)\n",
    "# The mean squared error\n",
    "print(\"Lasso Mean squared error: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred_L))\n",
    "print(\"Ridge Mean squared error: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred_R))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "#print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_pred, y_true):\n",
    "    # calculate error\n",
    "    denom = (abs(y_pred) + abs(y_true)) / 2\n",
    "    errors = abs(y_pred - y_true) / denom\n",
    "    return 100 * np.sum(errors) / len(y_true)\n",
    "\n",
    "print(smape(diabetes_y_pred,diabetes_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
